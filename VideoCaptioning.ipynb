{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05b9a6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "import random\n",
    "import joblib\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9206171",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'C:\\Users\\G Yuvan Shankar\\Desktop\\Project\\training_label.json') as data_file:    \n",
    "    y_data = json.load(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad04af7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list=[]\n",
    "vocab_list=[]\n",
    "train_split = 0.85\n",
    "for y in y_data:\n",
    "    for caption in y['caption']:\n",
    "        caption = \"<bos> \" + caption + \" <eos>\"\n",
    "        # we are only using sentences whose length lie between 6 and 10\n",
    "        if len(caption.split())>10 or len(caption.split())<6:\n",
    "            continue\n",
    "        else:\n",
    "            train_list.append([caption, y['id']])\n",
    "random.shuffle(train_list)\n",
    "training_list = train_list[:int(len(train_list)*train_split)]\n",
    "validation_list = train_list[int(len(train_list)*train_split):]\n",
    "for train in training_list:\n",
    "    vocab_list.append(train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e254f752",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model_path = r'feat\\model_final'\n",
    "num_decoder_tokens=1500\n",
    "with open(os.path.join(save_model_path, 'tokenizer' + str(num_decoder_tokens)), 'rb') as file:\n",
    "    tokenizer = joblib.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "430cde46",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_FEATURE_DIR = r'C:\\Users\\G Yuvan Shankar\\Desktop\\Project\\feat'\n",
    "x_data={}\n",
    "npyfilespath =r'C:\\Users\\G Yuvan Shankar\\Desktop\\Project\\feat'\n",
    "os.chdir(npyfilespath)\n",
    "for npfile in glob.glob(\"*.npy\"):\n",
    "    filepath = os.path.join(npyfilespath, npfile)\n",
    "    f= np.load(filepath)\n",
    "    x_data[npfile[:-4]] = f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78b3aaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_datatest(train_path, epochs=150, x_data=x_data, tokenizer=tokenizer, num_decoder_tokens=1500,training_list=training_list, batch_size=160, maxlen=10):\n",
    "    encoder_input_data = []\n",
    "    decoder_input_data = []\n",
    "    decoder_target_data = []\n",
    "    videoId = []\n",
    "    videoSeq = []\n",
    "    for idx, cap in enumerate(training_list):\n",
    "        caption = cap[0]\n",
    "        videoId.append(cap[1])\n",
    "        videoSeq.append(caption)\n",
    "    train_sequences = tokenizer.texts_to_sequences(videoSeq)\n",
    "    train_sequences = np.array(train_sequences)\n",
    "    train_sequences = pad_sequences(train_sequences, padding='post',truncating='post', maxlen=maxlen)\n",
    "    max_seq_length = train_sequences.shape[1]\n",
    "    filesize = len(train_sequences)\n",
    "    X_data = []\n",
    "    y_data = []\n",
    "    n = 0\n",
    "    for i in range(epochs):\n",
    "        for idx in  range(0,filesize):\n",
    "            n += 1\n",
    "            encoder_input_data.append(x_data[videoId[idx]])\n",
    "            y = to_categorical(train_sequences[idx], num_decoder_tokens)\n",
    "            decoder_input_data.append(y[:-1])\n",
    "            decoder_target_data.append(y[1:])\n",
    "            if n == batch_size:\n",
    "                encoder_input = np.array(encoder_input_data)\n",
    "                decoder_input = np.array(decoder_input_data)\n",
    "                decoder_target = np.array(decoder_target_data)\n",
    "                encoder_input_data = []\n",
    "                decoder_input_data = []\n",
    "                decoder_target_data = []\n",
    "                n = 0\n",
    "                yield ([encoder_input, decoder_input], decoder_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b95de2e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_inputs (InputLayer)     [(None, 80, 4096)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_inputs (InputLayer)     [(None, 10, 1500)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "endcoder_lstm (LSTM)            [(None, 80, 512), (N 9439232     encoder_inputs[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder_lstm (LSTM)             [(None, 10, 512), (N 4122624     decoder_inputs[0][0]             \n",
      "                                                                 endcoder_lstm[0][1]              \n",
      "                                                                 endcoder_lstm[0][2]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_relu (Dense)            (None, 10, 1500)     769500      decoder_lstm[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 14,331,356\n",
      "Trainable params: 14,331,356\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "time_steps_encoder=80\n",
    "num_encoder_tokens=4096\n",
    "latent_dim=512\n",
    "time_steps_decoder=10\n",
    "num_decoder_tokens=1500\n",
    "\n",
    "# Setting up the encoder\n",
    "encoder_inputs = Input(shape=(time_steps_encoder, num_encoder_tokens), name=\"encoder_inputs\")\n",
    "encoder = LSTM(latent_dim, return_state=True,return_sequences=True, name='endcoder_lstm')\n",
    "_, state_h, state_c = encoder(encoder_inputs)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "\n",
    "# Set up the decoder\n",
    "decoder_inputs = Input(shape=(time_steps_decoder, num_decoder_tokens), name= \"decoder_inputs\")\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True, name='decoder_lstm')\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax', name='decoder_relu')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model=load_model('modelfinal.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "001c7f33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2583"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(validation_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0ad83b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\G Yuvan Shankar\\anaconda3\\envs\\gpu\\lib\\site-packages\\ipykernel_launcher.py:12: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 91 steps, validate for 16 steps\n",
      "Epoch 1/150\n",
      "41/91 [============>.................] - ETA: 17:28 - loss: 1.0362 - accuracy: 0.7372\n",
      "W: interrupt received, stopping\n"
     ]
    }
   ],
   "source": [
    "train = load_datatest(train_path='training_data',batch_size=160, training_list=training_list, x_data=x_data, epochs=150)\n",
    "valid = load_datatest(train_path='training_data',batch_size=160, training_list=validation_list, x_data=x_data, epochs=150)\n",
    "opt = optimizers.Adam(lr=0.0003)\n",
    "model.compile(metrics=['accuracy'], optimizer=opt, loss='categorical_crossentropy')\n",
    "batch_size=160\n",
    "try:\n",
    "    model.fit(train,validation_data=valid,validation_steps=(len(validation_list)//batch_size),epochs=150,steps_per_epoch=(len(training_list)//batch_size))\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nW: interrupt received, stopping\")\n",
    "finally:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f3e0ab65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_inputs (InputLayer)  [(None, 80, 4096)]        0         \n",
      "_________________________________________________________________\n",
      "endcoder_lstm (LSTM)         [(None, 80, 512), (None,  9439232   \n",
      "=================================================================\n",
      "Total params: 9,439,232\n",
      "Trainable params: 9,439,232\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "decoder_inputs (InputLayer)     [(None, 10, 1500)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_lstm (LSTM)             [(None, 10, 512), (N 4122624     decoder_inputs[0][0]             \n",
      "                                                                 input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "decoder_relu (Dense)            (None, 10, 1500)     769500      decoder_lstm[1][0]               \n",
      "==================================================================================================\n",
      "Total params: 4,892,124\n",
      "Trainable params: 4,892,124\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.\n",
      "Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "save_model_path = 'model_final'\n",
    "if not os.path.exists(save_model_path):\n",
    "    os.makedirs(save_model_path)\n",
    "# Saving encoder as in training\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "# Saving decoder states and dense layer \n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "    decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states)\n",
    "encoder_model.summary()\n",
    "decoder_model.summary()\n",
    "encoder_model.save(os.path.join(save_model_path, 'encoder_model.h5'))\n",
    "decoder_model.save_weights(os.path.join(save_model_path, 'decoder_model_weights.h5'))\n",
    "with open(os.path.join(save_model_path,'tokenizer'+ str(num_decoder_tokens) ),'wb') as file:\n",
    "    joblib.dump(tokenizer, file)\n",
    "plot_model(encoder_model, to_file='model_inference_encoder.png', show_shapes=True, show_layer_names=True)\n",
    "plot_model(decoder_model, to_file='model_inference_decoder.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "80ae7450",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2baf10e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class to perform inference on all test files and save as test_output.txt\n",
    "import pickle, functools, operator\n",
    "class Video2Text(object):\n",
    "    ''' Initialize the parameters for the model '''\n",
    "    def __init__(self):\n",
    "        self.latent_dim = 512\n",
    "        self.num_encoder_tokens = 4096\n",
    "        self.num_decoder_tokens = 1500\n",
    "        self.time_steps_encoder = 80\n",
    "        self.time_steps_decoder = None\n",
    "        self.preload = True\n",
    "        self.preload_data_path = 'preload_data'\n",
    "        self.max_probability = -1\n",
    "\n",
    "        # processed data\n",
    "        self.encoder_input_data = []\n",
    "        self.decoder_input_data = []\n",
    "        self.decoder_target_data = []\n",
    "        self.tokenizer = None\n",
    "\n",
    "        # models\n",
    "        self.encoder_model = None\n",
    "        self.decoder_model = None\n",
    "        self.inf_encoder_model = None\n",
    "        self.inf_decoder_model = None\n",
    "        self.save_model_path = 'model_final'\n",
    "        self.test_path = 'testing_data'\n",
    "        self.search_type='greedy'\n",
    "    def load_inference_models(self):\n",
    "        # load tokenizer\n",
    "        \n",
    "        with open(os.path.join(self.save_model_path, 'tokenizer' + str(self.num_decoder_tokens)), 'rb') as file:\n",
    "            self.tokenizer = joblib.load(file)\n",
    "\n",
    "        # inference encoder model\n",
    "        self.inf_encoder_model = load_model(os.path.join(self.save_model_path, 'encoder_model.h5'))\n",
    "\n",
    "        # inference decoder model\n",
    "        decoder_inputs = Input(shape=(None, self.num_decoder_tokens))\n",
    "        decoder_dense = Dense(self.num_decoder_tokens, activation='softmax')\n",
    "        decoder_lstm = LSTM(self.latent_dim, return_sequences=True, return_state=True)\n",
    "        decoder_state_input_h = Input(shape=(self.latent_dim,))\n",
    "        decoder_state_input_c = Input(shape=(self.latent_dim,))\n",
    "        decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "        decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
    "        decoder_states = [state_h, state_c]\n",
    "        decoder_outputs = decoder_dense(decoder_outputs)\n",
    "        self.inf_decoder_model = Model(\n",
    "            [decoder_inputs] + decoder_states_inputs,\n",
    "            [decoder_outputs] + decoder_states)\n",
    "        self.inf_decoder_model.load_weights(os.path.join(self.save_model_path, 'decoder_model_weights.h5'))\n",
    "    \n",
    "    def decode_sequence2bs(self, input_seq):\n",
    "        states_value = self.inf_encoder_model.predict(input_seq)\n",
    "        target_seq = np.zeros((1, 1, self.num_decoder_tokens))\n",
    "        target_seq[0, 0, self.tokenizer.word_index['bos']] = 1\n",
    "        self.beam_search(target_seq, states_value,[],[],0)\n",
    "        return decode_seq\n",
    "    def greedy_search(self, f):\n",
    "        \"\"\"\n",
    "                :param f: the loaded numpy array after creating videos to frames and extracting features\n",
    "                :return: the final sentence which has been predicted greedily\n",
    "                \"\"\"\n",
    "        inv_map = self.index_to_word()\n",
    "        states_value = self.inf_encoder_model.predict(f.reshape(-1, 80, 4096))\n",
    "        target_seq = np.zeros((1, 1, 1500))\n",
    "        sentence = ''\n",
    "        target_seq[0, 0, self.tokenizer.word_index['bos']] = 1\n",
    "        for i in range(15):\n",
    "            output_tokens, h, c = self.inf_decoder_model.predict([target_seq] + states_value)\n",
    "            states_value = [h, c]\n",
    "            output_tokens = output_tokens.reshape(self.num_decoder_tokens)\n",
    "            y_hat = np.argmax(output_tokens)\n",
    "            if y_hat == 0:\n",
    "                continue\n",
    "            if inv_map[y_hat] is None:\n",
    "                break\n",
    "            else:\n",
    "                sentence = sentence + inv_map[y_hat] + ' '\n",
    "                target_seq = np.zeros((1, 1, 1500))\n",
    "                target_seq[0, 0, y_hat] = 1\n",
    "        return ' '.join(sentence.split()[:-1])\n",
    "\n",
    "    def decode_sequence2bs(self, input_seq):\n",
    "        states_value = self.inf_encoder_model.predict(input_seq)\n",
    "        target_seq = np.zeros((1, 1, self.num_decoder_tokens))\n",
    "        target_seq[0, 0, self.tokenizer.word_index['bos']] = 1\n",
    "        self.beam_search(target_seq, states_value, [], [], 0)\n",
    "        return decode_seq\n",
    "    def beam_search(self, target_seq, states_value, prob,  path, lens):\n",
    "        global decode_seq\n",
    "        node = 2\n",
    "        output_tokens, h, c = self.inf_decoder_model.predict(\n",
    "            [target_seq] + states_value)\n",
    "        output_tokens = output_tokens.reshape(self.num_decoder_tokens)\n",
    "        sampled_token_index = output_tokens.argsort()[-node:][::-1]\n",
    "        states_value = [h, c]\n",
    "        for i in range(node):\n",
    "            if sampled_token_index[i] == 0:\n",
    "                sampled_char = ''\n",
    "            else:\n",
    "                sampled_char = list(self.tokenizer.word_index.keys())[\n",
    "                    list(self.tokenizer.word_index.values()).index(sampled_token_index[i])]\n",
    "            MAX_LEN = 12\n",
    "            if sampled_char != 'eos' and lens <= MAX_LEN:\n",
    "                p = output_tokens[sampled_token_index[i]]\n",
    "                if sampled_char == '':\n",
    "                    p = 1\n",
    "                prob_new = list(prob)\n",
    "                prob_new.append(p)\n",
    "                path_new = list(path)\n",
    "                path_new.append(sampled_char)\n",
    "                target_seq = np.zeros((1, 1, self.num_decoder_tokens))\n",
    "                target_seq[0, 0, sampled_token_index[i]] = 1.\n",
    "                self.beam_search(target_seq, states_value, prob_new, path_new, lens + 1)\n",
    "            else:\n",
    "                p = output_tokens[sampled_token_index[i]]\n",
    "                prob_new = list(prob)\n",
    "                prob_new.append(p)\n",
    "                p = functools.reduce(operator.mul, prob_new, 1)\n",
    "                if p > self.max_probability:\n",
    "                    decode_seq = path\n",
    "                    self.max_probability = p\n",
    "\n",
    "    def decoded_sentence_tuning(self, decoded_sentence):\n",
    "        decode_str = []\n",
    "        filter_string = ['bos', 'eos']\n",
    "        unigram = {}\n",
    "        last_string = \"\"\n",
    "        for idx2, c in enumerate(decoded_sentence):\n",
    "            if c in unigram:\n",
    "                unigram[c] += 1\n",
    "            else:\n",
    "                unigram[c] = 1\n",
    "            if(last_string == c and idx2 > 0):\n",
    "                continue\n",
    "            if c in filter_string:\n",
    "                continue\n",
    "            if len(c) > 0:\n",
    "                decode_str.append(c)\n",
    "            if idx2 > 0:\n",
    "                last_string = c\n",
    "        return decode_str\n",
    "    def index_to_word(self):\n",
    "        # inverts word tokenizer\n",
    "        index_to_word = {value: key for key, value in self.tokenizer.word_index.items()}\n",
    "        return index_to_word\n",
    "    \n",
    "    def get_test_data(self, path):\n",
    "        X_test = []\n",
    "        X_test_filename = []\n",
    "        with open (os.path.join(path, 'testing_id.txt')) as testing_file:\n",
    "            lines = testing_file.readlines()\n",
    "            for filename in lines:\n",
    "                filename = filename.strip()\n",
    "                f = np.load(os.path.join(path , 'feat', filename + '.npy'))\n",
    "                X_test.append(f)\n",
    "                X_test_filename.append(filename[:-4])\n",
    "            X_test = np.array(X_test)\n",
    "        return X_test, X_test_filename\n",
    "\n",
    "    def test(self):\n",
    "        \"\"\"\n",
    "            writes the captions of all the testing videos in a text file\n",
    "        \"\"\"\n",
    "        X_test, X_test_filename = self.get_test_data(os.path.join(self.test_path))\n",
    "\n",
    "        # generate inference test outputs\n",
    "        with open(os.path.join(self.save_model_path, 'test_output.txt'), 'w') as file:\n",
    "            for idx, x in enumerate(X_test):\n",
    "                file.write(X_test_filename[idx] + ',')\n",
    "                if self.search_type is 'greedy':\n",
    "                    start = time.time()\n",
    "                    decoded_sentence = self.greedy_search(x.reshape(-1, 80, 4096))\n",
    "                    file.write(decoded_sentence + ',{:.2f}'.format(time.time()-start))\n",
    "                else:\n",
    "                    start = time.time()\n",
    "                    decoded_sentence = self.decode_sequence2bs(x.reshape(-1, 80, 4096))\n",
    "                    decode_str = self.decoded_sentence_tuning(decoded_sentence)\n",
    "                    for d in decode_str:\n",
    "                        file.write(d + ' ')\n",
    "                    file.write(',{:.2f}'.format(time.time() - start))\n",
    "                file.write('\\n')\n",
    "\n",
    "                # re-init max prob\n",
    "                self.max_probability = -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9aeb2619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "c = Video2Text()\n",
    "c.load_inference_models()\n",
    "c.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2db244",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
